---
published: true
title: Towards Risk Prediction via 3D Convolutional Neural Networks for Electronic Health Records
category: Machine Learning
tags: [Machine Learning, Algorithm, CNN]
layout: post
---

# Introduction

This is the paper I write with my teammates in my laborary. And now it's under revision.

# Abstract

In this paper, we investigate the usage of the convolutional neural network (CNN) in modeling longitudinal EHR data. Particularly, we propose a 3D CNN structure, which is featured by spatial pyramid pooling (SPP). Compared with methods of 2D CNNs, the proposed method can effectively and efficiently capture the complicated internal relations in EHRs. Besides, in previous work, the issue of variety in patient record length is addressed by padding zero all vectors to a fixed length. It is well handled with the spatial pyramid pooling, which divides the records into several length sections for respective pooling processing.


# METHODOLOGY

A. Input & Output
The raw input to our system is EHR data of each patient. The EHR data is composed of different medical events ar- ranged in chronological order. The length of EHR data vary from patient to patient, and each medical event is represented by a ordinal number like a word index in a vocabulary. The output of our system is the number 1 or 0, representing the patient has the targeted disease or not.
The following picture show the input structure:

![0](https://raw.githubusercontent.com/BigExcavator/coldsrh233.github.io/master/_posts/image/%233DCNN/0.jpg)
The size of filter in 3D convolution layer is 5×1×2×50. A window of the same size slides along the phrase sequence. As the picture shows, the convolution applied within each phrase makes the k × D matrix become a 2 length vector, and the convolution operation applied over the phrase sequence covers 5 phrases each time.

B. Data Preprocessing

First, we put the EHRs data of all patients into word2vec to build the embeddings. In our work, the embedding vector size is set to 50 and every medical feature get its precise vector representation. After this operation, the medical records of patients are represented by a list composed of many 50- length vectors. The data in this format is more conducive and convenient to be processed by the neural networks.

hen, we split the 2D medical records list of each patient into phrases of k (chosen from 1, 2, 3, 4) embedding vectors to fit into the 3D CNN model. Now a sequence of k-vectors phrases (3D) rather than a list of embedding vectors (2D) will be put into our network. On this condition, the 3D kernels could apply convolution operations over embedding vectors within each phrase and several adjacent phrases simultane- ously. 

C. The structure of our network

As mentioned above, the input to our network has been pre- trained with word2vec, and split into phrases. When k is equal to 3, the sequential length of input, representing the number of phrases, is choosing from [98,142,186,246]. To be specific, firstly, the input with size l × 1 × k × 50 enters C1, where 1 shows that the number of channels is 1 among input structure, which will be changed according to the filters’ number. The C1 has N1 filters of size 5×1×2×50, thus the output size of C1 layer is (l−4)×N1 ×(k−1)×1 (obviously the output matrix has N1 channels due to C1’s filters). When the data enters the first pooling layer, since the pooling layer will apply different pooling rate according to data’s length, we tentatively use l′ ×N1 ×k′ ×1 to denote the output of S1 layer (notice that l′ and k′ are the division results of S1 input). Subsequently, the output of S1 enters the C2 layer, whose kernel has N2 filters with size 2 × N1 × 1 × 1. Based on the same mechanism, the output size of C2 is (l′ −1)×N2 ×k′ ×1. In the S2 layer, according to our pre-determined, the output size of S2 is 12×N2 ×1×1. It is clear that we can get the fixed- size output no matter what the size of input is. Between the S2andthefinalfullconnectionlayer(F1),webuildpyramid structure in every channel to extract the features from multi- angles. To form the pyramid model, we apply a 6-max pooling and a 4-max pooling operation on the S2’s output respectively (only aimed at the sequential dimension). Thus, we obtain three feature maps: the 12, 3, 2 in the sequential dimension, and all of them are concatenated and flattened to be sent into full connection layer. Finally in the full connection layer, the data will be reshaped to a one dimension vector with the size N2×17×1×1, and then be processed to get the final prediction result.

The following picture shows the detailed structure:

![1](https://raw.githubusercontent.com/BigExcavator/coldsrh233.github.io/master/_posts/image/%233DCNN/1.jpg)

The following picture shows the pooling operation:


![2](https://raw.githubusercontent.com/BigExcavator/coldsrh233.github.io/master/_posts/image/%233DCNN/2.jpg)


# Our results

We compare our results with other baseline:

![3](https://raw.githubusercontent.com/BigExcavator/coldsrh233.github.io/master/_posts/image/%233DCNN/3.jpg)

And make comparsion between different version of our own model:

![4](https://raw.githubusercontent.com/BigExcavator/coldsrh233.github.io/master/_posts/image/%233DCNN/4.jpg)

![5](https://raw.githubusercontent.com/BigExcavator/coldsrh233.github.io/master/_posts/image/%233DCNN/5.jpg)

# Conclusion

We developed a 3D CNN-SPP model for risk prediction in this paper. The model extracts features from both spatial and temporal dimensions by performing 3D convolutions and 3D poolings alternatingly. We also introduced SPP to process multi-sized input records to solve the problem of length variety largely. We found that embedding the EHRs data into vectors and splitting the original records of each patient into phrases are very effective in boosting the performance. We evaluated the 3D CNN-SPP models on the pretreated data and demonstrate its superior performance to the state-of-the-art models and make great early predictions. In addition, a series of contrast tests showed that the model with 2 convolution layers and small mini-batch can lead to the best result.

It would be interesting to exploit the underlying information of the features throughout the whole algorithm and it’s worth to explore the unsupervised training method in the future. Applying 3D CNN-SPP model in other fields and scenarios are also promising.







